{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled35.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOFhwQGFOzZEPzYKuPe+gUG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raviintechis/-Email_Spam_Detection/blob/main/Untitled35.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3tcp8H3Nun6"
      },
      "source": [
        "#Import the libraries \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import string"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "tJuKu2jhuje2",
        "outputId": "0ed8708b-c1b3-4bed-e0d8-577fbb7d80db"
      },
      "source": [
        "#Load the data and print the first 5 rows\n",
        "df = pd.read_csv(\"emails.csv\")\n",
        "df.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>spam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Subject: naturally irresistible your corporate...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Subject: the stock trading gunslinger  fanny i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Subject: unbelievable new homes made easy  im ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Subject: 4 color printing special  request add...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Subject: do not have money , get software cds ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  spam\n",
              "0  Subject: naturally irresistible your corporate...     1\n",
              "1  Subject: the stock trading gunslinger  fanny i...     1\n",
              "2  Subject: unbelievable new homes made easy  im ...     1\n",
              "3  Subject: 4 color printing special  request add...     1\n",
              "4  Subject: do not have money , get software cds ...     1"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qcM8VbTvvh7",
        "outputId": "5f7cc729-1add-4afc-cf59-341039ca0962"
      },
      "source": [
        "#Now letâ€™s explore the data and get the number of rows & columns \n",
        "df.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5728, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gz2HMCJv_5f",
        "outputId": "dd445bfe-a66f-44be-b78d-17e0bacf6ba8"
      },
      "source": [
        "#To get the column names in the data set\n",
        "df.columns"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['text', 'spam'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5kjf6ElwCNP",
        "outputId": "82bacd5e-8242-41a6-fb1c-70fdb0264694"
      },
      "source": [
        "#To check for duplicates and remove them\n",
        "df.drop_duplicates(inplace=True)\n",
        "print(df.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5695, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W21JpZ3NwuA6",
        "outputId": "41eecf04-46cc-463b-a782-abd8523f8b5e"
      },
      "source": [
        "#To see the number of missing data for each column\n",
        "print(df.isnull().sum())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text    0\n",
            "spam    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTQrgP8ww4So",
        "outputId": "e471df7c-78c7-4c07-c5f4-ff219293f36c"
      },
      "source": [
        "# download the stopwords package\n",
        "nltk.download(\"stopwords\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7b6Psr5kxA_8",
        "outputId": "bb0f2024-1a73-4307-d774-2dc6f9e35c88"
      },
      "source": [
        "\"\"\" Now Create a function to clean the text and return the tokens. The cleaning of the text can be done by first removing punctuation and then removing the useless words also known as stop words.\"\"\"\n",
        "\n",
        "def process(text):\n",
        "    nopunc = [char for char in text if char not in string.punctuation]\n",
        "    nopunc = ''.join(nopunc)\n",
        "\n",
        "    clean = [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]\n",
        "    return clean\n",
        "# to show the tokenization\n",
        "df['text'].head().apply(process)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [Subject, naturally, irresistible, corporate, ...\n",
              "1    [Subject, stock, trading, gunslinger, fanny, m...\n",
              "2    [Subject, unbelievable, new, homes, made, easy...\n",
              "3    [Subject, 4, color, printing, special, request...\n",
              "4    [Subject, money, get, software, cds, software,...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkuxKe4h39Ee"
      },
      "source": [
        "#Now convert the text into a matrix of token counts\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "message = CountVectorizer(analyzer=process).fit_transform(df['text'])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWU6uvH04M1R",
        "outputId": "7cdf8a98-b01c-43c1-b80c-01828417cd09"
      },
      "source": [
        "#split the data into 80% training and 20% testing\n",
        "from sklearn.model_selection import train_test_split\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(message, df['spam'], test_size=0.20, random_state=0)\n",
        "# To see the shape of the data\n",
        "print(message.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5695, 37229)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62KetlMe4aiQ"
      },
      "source": [
        "# create and train the Naive Bayes Classifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "classifier = MultinomialNB().fit(xtrain, ytrain)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_UofsNg8Sb6",
        "outputId": "31655486-282e-43e6-b896-67ed49f11179"
      },
      "source": [
        "print(classifier.predict(xtrain))\n",
        "print(ytrain.values)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 ... 0 0 0]\n",
            "[0 0 0 ... 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2o45tjdx9f9Q",
        "outputId": "2c115b9c-270b-4bb3-db49-7faa6752cab5"
      },
      "source": [
        "# Evaluating the model on the training data set\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "pred = classifier.predict(xtrain)\n",
        "print(classification_report(ytrain, pred))\n",
        "print()\n",
        "print(\"Confusion Matrix: \\n\", confusion_matrix(ytrain, pred))\n",
        "print(\"Accuracy: \\n\", accuracy_score(ytrain, pred))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      3457\n",
            "           1       0.99      1.00      0.99      1099\n",
            "\n",
            "    accuracy                           1.00      4556\n",
            "   macro avg       0.99      1.00      1.00      4556\n",
            "weighted avg       1.00      1.00      1.00      4556\n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[3445   12]\n",
            " [   1 1098]]\n",
            "Accuracy: \n",
            " 0.9971466198419666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_8FmNrq9kgt",
        "outputId": "6fceed91-6d1c-42d4-b75f-032cdbcb1310"
      },
      "source": [
        "#print the predictions\n",
        "print(classifier.predict(xtest))\n",
        "#print the actual values\n",
        "print(ytest.values)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 0 ... 0 0 0]\n",
            "[1 0 0 ... 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSn08R-v9v_f",
        "outputId": "770e63a2-e107-42d0-c91c-4917c099b611"
      },
      "source": [
        "# Evaluating the model on the training data set\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "pred = classifier.predict(xtest)\n",
        "print(classification_report(ytest, pred))\n",
        "print()\n",
        "print(\"Confusion Matrix: \\n\", confusion_matrix(ytest, pred))\n",
        "print(\"Accuracy: \\n\", accuracy_score(ytest, pred))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99       870\n",
            "           1       0.97      1.00      0.98       269\n",
            "\n",
            "    accuracy                           0.99      1139\n",
            "   macro avg       0.98      0.99      0.99      1139\n",
            "weighted avg       0.99      0.99      0.99      1139\n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[862   8]\n",
            " [  1 268]]\n",
            "Accuracy: \n",
            " 0.9920983318700615\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_-_HAy190_c"
      },
      "source": [
        "#The classifier accurately identified the email messages as spam or not spam with 99.2 % accuracy on the test data."
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cdkB3R9-EnC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}